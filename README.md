# Vision-In-Transformer-Model
Apply Transformer Models to Computer Vision Tasks

The implementation about relative position embedding can refer to:

https://theaisummer.com/positional-embeddings/: BoT position embedding method (refer to BoT_Position_Embedding.png and BoT_Position_Embedding(2).png)

Swin Transformer position embedding refer to Swin_Transformer_Position_Embedding.png

The implementation detail about Swin Transformer can refer to:

https://zhuanlan.zhihu.com/p/361366090

One Swin Transformer Block = Swin_Transformer_Stage

Swin_Transformer_Stage = Swin_Transformer + Patch_Merge


Pyramid Vision Transformer-v2 is coming soon !!! 


paper reading now:

CoAtNet: Marrying Convolution and Attention for All Data Sizes

Twins: Revisiting the Design of Spatial Attention in Vision Transformers

If you have any question, please send email to me:

xingshuli600@gmail.com
